from flask import Flask, render_template, request, jsonify, session
import sys
import os
import json
import shutil
import tempfile
from datetime import datetime
import secrets
from werkzeug.utils import secure_filename

# Add parent directory to path to import memcontext
# Ensure the path is /root/autodl-tmp for consistent imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Import memcontext modules directly
from memcontext import Memcontext
# Import utils directly from the playground directory
from utils import get_timestamp
from multimodal.converters.video_converter import VideoConverter

app = Flask(__name__)
app.secret_key = secrets.token_hex(16)

# Global memcontext instance (in production, you'd use proper session management)
memory_systems = {}

# 删除了固定的API_KEY, BASE_URL, MODEL

# 有效邀请码列表 - 在实际部署中应该存储在数据库或加密文件中
# VALID_INVITE_CODES = [
#     'DEMO2024',
#     'MEMORY001',
#     'TESTUSER',
#     'BETA2024',
#     'INVITE123'
# ]

# def load_invite_codes():
#     """从文件加载邀请码列表"""
#     invite_codes_file = os.path.join(os.path.dirname(__file__), 'invite_codes.json')
#     try:
#         if os.path.exists(invite_codes_file):
#             with open(invite_codes_file, 'r', encoding='utf-8') as f:
#                 return json.load(f)
#         else:
#             # 如果文件不存在，创建默认邀请码文件
#             with open(invite_codes_file, 'w', encoding='utf-8') as f:
#                 json.dump(VALID_INVITE_CODES, f, ensure_ascii=False, indent=2)
#             return VALID_INVITE_CODES
#     except Exception as e:
#         print(f"Error loading invite codes: {e}")
#         return VALID_INVITE_CODES

# def save_invite_codes(codes):
#     """保存邀请码列表到文件"""
#     invite_codes_file = os.path.join(os.path.dirname(__file__), 'invite_codes.json')
#     try:
#         with open(invite_codes_file, 'w', encoding='utf-8') as f:
#             json.dump(codes, f, ensure_ascii=False, indent=2)
#     except Exception as e:
#         print(f"Error saving invite codes: {e}")

# 启动时加载邀请码
# VALID_INVITE_CODES = load_invite_codes()

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/init_memory', methods=['POST'])
def init_memory():
    data = request.json
    user_id = data.get('user_id', '').strip()
    api_key = data.get('api_key', '').strip()
    base_url = data.get('base_url', '').strip()
    model = data.get('model_name', '').strip()
    siliconflow_key = data.get('siliconflow_key', '').strip()

    if not user_id or not api_key or not base_url or not model:
        return jsonify({'error': 'User ID, API Key, Base URL, and Model Name are required.'}), 400
    
    assistant_id = f"assistant_{user_id}"
    embedding_kwargs = {}
    if siliconflow_key:
        os.environ['SILICONFLOW_API_KEY'] = siliconflow_key
        embedding_kwargs = {
            'use_siliconflow': True,
            'siliconflow_model': "BAAI/bge-m3"
        }
    elif os.environ.get('SILICONFLOW_API_KEY'):
        embedding_kwargs = {
            'use_siliconflow': True,
            'siliconflow_model': "BAAI/bge-m3"
        }
    
    try:
        # Initialize memcontext for this session
        data_path = './data'
        os.makedirs(data_path, exist_ok=True)
        
        memory_system = Memcontext(
            user_id=user_id,
            openai_api_key=api_key,
            openai_base_url=base_url,
            data_storage_path=data_path,
            assistant_id=assistant_id,  # 使用邀请码作为assistant_id
            short_term_capacity=15,  # Smaller for demo
            mid_term_capacity=200,   # Smaller for demo
            long_term_knowledge_capacity=1000,  # Smaller for demo
            mid_term_heat_threshold=10.0,
            # embedding_model_name="/root/autodl-tmp/embedding_cache/models--BAAI--bge-m3/snapshots/5617a9f61b028005a4858fdac845db406aefb181",  # 降低阈值，更容易触发长期记忆更新（原默认值为5.0）
            embedding_model_name="BAAI/bge-m3",  # 使用模型名称，会自动下载或远程请求
            embedding_model_kwargs=embedding_kwargs,
            llm_model=model
        )
        
        session_id = secrets.token_hex(8)
        memory_systems[session_id] = memory_system
        session['memory_session_id'] = session_id
        # 将配置存入session
        session['memory_config'] = {
            'api_key': api_key,
            'base_url': base_url,
            'model': model,
            'embedding_provider': 'siliconflow' if embedding_kwargs.get('use_siliconflow') else 'local'
        }
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'user_id': user_id,
            'assistant_id': assistant_id,
            'model': model,
            'base_url': base_url,
            'embedding_provider': session['memory_config']['embedding_provider']
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    user_input = data.get('message', '')
    #这里新加了补充metadata的功能(如果有metadata字段的话)
    #    user_input = data.get('message', '')
    user_conversation_meta_data = data.get('metadata', None)
    relationship_with_user = data.get('relationship', 'friend')
    
    session_id = session.get('memory_session_id')
    if not session_id or session_id not in memory_systems:
        return jsonify({'error': 'Memory system not initialized'}), 400
    
    memory_system = memory_systems[session_id]
    
    try:
        # 原代码：
        # Get response from memcontext (this already adds the memory internally)
        # response = memory_system.get_response(user_input)
        
        # 新代码：传递 metadata 和 relationship 参数
        response = memory_system.get_response(
            query=user_input,
            relationship_with_user=relationship_with_user,
            user_conversation_meta_data=user_conversation_meta_data
        )
        
        # Do NOT add memory again here - it's already done in get_response()
        
        return jsonify({
            'response': response,
            'timestamp': get_timestamp()
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/add_multimodal_memory', methods=['POST'])
def add_multimodal_memory_endpoint():
    session_id = session.get('memory_session_id')
    if not session_id or session_id not in memory_systems:
        return jsonify({'error': 'Memory system not initialized'}), 400

    memory_system = memory_systems[session_id]
    cleanup_paths = []

    try:
        converter_type = None
        agent_response = None
        converter_kwargs = {}

        if request.content_type and 'multipart/form-data' in request.content_type:
            uploaded_file = request.files.get('file')
            if not uploaded_file or not uploaded_file.filename:
                return jsonify({'error': 'File upload is required.'}), 400

            safe_name = secure_filename(uploaded_file.filename)
            temp_dir = tempfile.mkdtemp(prefix="memcontext_upload_")
            temp_path = os.path.join(temp_dir, safe_name or "upload.bin")
            uploaded_file.save(temp_path)
            cleanup_paths.append(temp_dir)

            source = temp_path
            source_type = 'file_path'
            agent_response = request.form.get('agent_response')
            converter_type = request.form.get('converter_type')
            if request.form.get('converter_kwargs'):
                try:
                    converter_kwargs = json.loads(request.form['converter_kwargs'])
                except json.JSONDecodeError:
                    return jsonify({'error': 'converter_kwargs must be valid JSON'}), 400
        else:
            data = request.get_json(silent=True) or {}
            if data.get('file_path'):
                source = data['file_path']
                source_type = 'file_path'
            elif data.get('url'):
                source = data['url']
                source_type = 'url'
            else:
                return jsonify({'error': 'file_path or url must be provided'}), 400

            converter_type = data.get('converter_type')
            agent_response = data.get('agent_response')
            converter_kwargs = data.get('converter_kwargs', {})

        if source_type != 'file_path':
            return jsonify({'error': '当前仅支持本地文件路径(file_path)的视频源'}), 400

        converter_type = (converter_type or 'video').lower()
        if converter_type not in ('video', 'videorag'):
            return jsonify({'error': f'不支持的 converter_type: {converter_type}，可选 video | videorag'}), 400

        converter_settings = dict(converter_kwargs or {})
        deepseek_key = converter_settings.pop('deepseek_key', None)
        silicon_key = converter_settings.pop('siliconflow_key', None)
        if deepseek_key:
            os.environ['DEEPSEEK_API_KEY'] = deepseek_key
        if silicon_key:
            os.environ['SILICONFLOW_API_KEY'] = silicon_key

        converter_settings.setdefault('working_dir', './videorag-workdir')
        progress_events = []

        def progress_callback(progress: float, message: str) -> None:
            progress_events.append({
                'progress': round(float(progress), 4),
                'message': message
            })
        print(converter_settings)
        print(f"progress_callback: {progress_callback}")

        if converter_type == 'videorag':
            converter = VideoRAGConverter(progress_callback=progress_callback, **converter_settings)
        else:
            converter = VideoConverter(progress_callback=progress_callback, **converter_settings)

        print(f"converter: {converter}")
        video_result = converter.convert(
            source,
            source_type='file_path',
            **converter_settings,
        )
        print(f"video_result: {video_result}")
        if video_result.status != 'success':
            return jsonify({
                'error': video_result.error or 'VideoRAG 处理失败',
                'metadata': video_result.metadata,
                'progress': progress_events
            }), 500

        conversations = []
        for chunk in video_result.chunks:
            chunk_meta = dict(chunk.metadata)
            # 原代码（已注释）：
            # meta_data = {
            #     'source_type': chunk_meta.get('source_type', 'file_path'),
            #     'video_name': chunk_meta.get('video_name', ''),
            #     'time_range': chunk_meta.get('time_range', ''),
            # }
            
            # 新代码：保存完整的 metadata 信息，包括所有有用的字段
            # 统一生成 name 字段：文件名 + chunk_index
            base_video_name = chunk_meta.get('video_name') or chunk_meta.get('original_filename', '')
            chunk_idx = chunk_meta.get('chunk_index', 0)
            if base_video_name:
                name_field = f"{base_video_name}_chunk_{chunk_idx}"
                # 避免重复附加 chunk_XX
                if f"chunk_{chunk_idx}" in base_video_name:
                    name_field = base_video_name
            else:
                name_field = f"video_chunk_{chunk_idx}"

            meta_data = {
                'source_type': chunk_meta.get('source_type', 'file_path'),
                'video_name': chunk_meta.get('video_name', ''),
                'name': name_field,
                'time_range': chunk_meta.get('time_range', ''),
                # 内容分析字段
                'chunk_summary': chunk_meta.get('chunk_summary', ''),
                'scene_label': chunk_meta.get('scene_label', ''),
                'objects_detected': chunk_meta.get('objects_detected', []),
                'actions': chunk_meta.get('actions', ''),
                'emotions': chunk_meta.get('emotions', ''),
                # 技术字段
                'duration_seconds': chunk_meta.get('duration_seconds', 0),
                'chunk_index': chunk_meta.get('chunk_index', 0),
                'chunk_count_estimate': chunk_meta.get('chunk_count_estimate', 0),
                'language': chunk_meta.get('language', ''),
                'confidence': chunk_meta.get('confidence', 0.75),
            }

            # 优先使用 chunk.text（完整内容），如果没有则使用 chunk_summary（摘要）
            chunk_text = chunk.text.strip() if chunk.text else ''
            chunk_summary = chunk_meta.get('chunk_summary', '').strip()
            agent_reply = chunk_text or chunk_summary or '该视频片段未生成可用摘要'
            
            video_name = meta_data['video_name']
            time_range = meta_data['time_range']
            user_input = f"{video_name}, {time_range}发生了什么？"

            timestamp = get_timestamp()
            # 去重：如果 short-term 中已有相同 video_name 和 time_range 的记忆，则跳过添加
            existing = False
            try:
                for m in memory_system.short_term_memory.get_all():
                    m_md = m.get('meta_data', {}) or {}
                    if (
                        m_md.get('video_name') == meta_data.get('video_name')
                        and m_md.get('time_range') == meta_data.get('time_range')
                    ):
                        existing = True
                        break
            except Exception:
                existing = False

            if not existing:
                memory_system.add_memory(
                    user_input=user_input,
                    agent_response=agent_reply,
                    timestamp=timestamp,
                    meta_data=meta_data
                )
            else:
                print(f"Skipping duplicate memory for {meta_data.get('video_name')} {meta_data.get('time_range')}")

            conversations.append({
                'user_input': user_input,
                'agent_response': agent_reply,
                'timestamp': timestamp,
                'meta_data': meta_data
            })

        return jsonify({
            'success': True,
            'ingested_rounds': len(conversations),
            'conversations': conversations,
            'videorag_metadata': video_result.metadata,
            'progress': progress_events
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500
    finally:
        for path in cleanup_paths:
            try:
                shutil.rmtree(path, ignore_errors=True)
            except Exception:
                pass

@app.route('/memory_state', methods=['GET'])
def get_memory_state():
    session_id = session.get('memory_session_id')
    if not session_id or session_id not in memory_systems:
        return jsonify({'error': 'Memory system not initialized'}), 400
    
    memory_system = memory_systems[session_id]
    
    try:
        # Get short-term memory
        short_term = memory_system.short_term_memory.get_all()
        mid_term_sessions = []
        # Get mid-term memory sessions (top 5)
        for sid, session_data in list(memory_system.mid_term_memory.sessions.items())[:5]:
            mid_term_sessions.append({
                'id': sid,
                'summary': session_data.get('summary', ''),
                'keywords': session_data.get('summary_keywords', []),
                'heat': session_data.get('H_segment', 0),
                'visit_count': session_data.get('N_visit', 0),
                'last_visit': session_data.get('last_visit_time', ''),
                'page_count': len(session_data.get('details', []))
            })
        
        # Sort by heat
        mid_term_sessions.sort(key=lambda x: x['heat'], reverse=True)
        
        # Get long-term memory - separate user profile, user knowledge, and assistant knowledge
        user_profile = memory_system.user_long_term_memory.get_raw_user_profile(memory_system.user_id)
        user_knowledge = memory_system.user_long_term_memory.get_user_knowledge()
        assistant_knowledge = memory_system.assistant_long_term_memory.get_assistant_knowledge()
        return jsonify({
            'short_term': {
                'capacity': memory_system.short_term_memory.max_capacity,
                'current_count': len(short_term),
                'memories': short_term
            },
            'mid_term': {
                'capacity': memory_system.mid_term_memory.max_capacity,
                'current_count': len(memory_system.mid_term_memory.sessions),
                'sessions': mid_term_sessions,
                'heat_threshold': memory_system.mid_term_heat_threshold
            },
            'long_term': {
                'user_profile': user_profile,
                'user_knowledge': [k.get('knowledge', '') for k in user_knowledge],
                'assistant_knowledge': [k.get('knowledge', '') for k in assistant_knowledge]
            }
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/trigger_analysis', methods=['POST'])
def trigger_analysis():
    session_id = session.get('memory_session_id')
    if not session_id or session_id not in memory_systems:
        return jsonify({'error': 'Memory system not initialized'}), 400
    
    memory_system = memory_systems[session_id]
    
    try:
        # Check if there are any mid-term memory sessions to analyze
        if not memory_system.mid_term_memory.sessions:
            return jsonify({'error': 'No Mid-term memory, but at least keep short-term memory for seven rounds.'}), 400
        
        # Check if there are any unanalyzed pages in mid-term memory
        has_unanalyzed_pages = False
        for session_data in memory_system.mid_term_memory.sessions.values():
            unanalyzed_pages = [p for p in session_data.get('details', []) if not p.get('analyzed', False)]
            if unanalyzed_pages:
                has_unanalyzed_pages = True
                break
        
        if not has_unanalyzed_pages:
            return jsonify({'error': 'No Mid-term memory, but at least keep short-term memory for seven rounds.'}), 400
        
        # Force mid-term analysis
        memory_system.force_mid_term_analysis()
        return jsonify({'success': True, 'message': 'Analysis triggered successfully'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/personality_analysis', methods=['POST'])
def personality_analysis():
    session_id = session.get('memory_session_id')
    if not session_id or session_id not in memory_systems:
        return jsonify({'error': 'Memory system not initialized'}), 400
    
    memory_system = memory_systems[session_id]
    
    try:
        # Get user profile
        user_profile = memory_system.user_long_term_memory.get_raw_user_profile(memory_system.user_id)
        
        if not user_profile or user_profile.lower() in ['none', 'no profile data yet']:
            return jsonify({'error': 'No user profile available for analysis'}), 400
        
        # Parse personality traits from the user profile
        personality_analysis = parse_personality_traits(user_profile)
        
        return jsonify({
            'success': True,
            'personality_analysis': personality_analysis
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def parse_personality_traits(user_profile):
    """
    Parse personality traits from user profile text.
    Extract traits in format: Dimension ( Level(High/Medium/Low) )
    """
    # Define the three main categories
    categories = {
        'Psychological Model': [
            'Extraversion', 'Openness', 'Agreeableness', 'Conscientiousness', 'Neuroticism',
            'Physiological Needs', 'Need for Security', 'Need for Belonging', 'Need for Self-Esteem',
            'Cognitive Needs', 'Aesthetic Appreciation', 'Self-Actualization', 'Need for Order',
            'Need for Autonomy', 'Need for Power', 'Need for Achievement'
        ],
        'AI Alignment Dimensions': [
            'Helpfulness', 'Honesty', 'Safety', 'Instruction Compliance', 'Truthfulness',
            'Coherence', 'Complexity', 'Conciseness'
        ],
        'Content Platform Interest Tags': [
            'Science Interest', 'Education Interest', 'Psychology Interest', 'Family Concern',
            'Fashion Interest', 'Art Interest', 'Health Concern', 'Financial Management Interest',
            'Sports Interest', 'Food Interest', 'Travel Interest', 'Music Interest',
            'Literature Interest', 'Film Interest', 'Social Media Activity', 'Tech Interest',
            'Environmental Concern', 'History Interest', 'Political Concern', 'Religious Interest',
            'Gaming Interest', 'Animal Concern', 'Emotional Expression', 'Sense of Humor',
            'Information Density', 'Language Style', 'Practicality'
        ]
    }
    
    # Extract traits from user profile
    extracted_traits = {}
    
    import re
    
    # Look for patterns like "Dimension ( Level(High/Medium/Low) )"
    pattern = r'([A-Za-z\s]+)\s*\(\s*([A-Za-z]+)\s*\)'
    matches = re.findall(pattern, user_profile)
    
    for match in matches:
        dimension = match[0].strip()
        level = match[1].strip()
        
        # Find which category this dimension belongs to
        for category, dimensions in categories.items():
            for cat_dimension in dimensions:
                if dimension.lower() in cat_dimension.lower() or cat_dimension.lower() in dimension.lower():
                    if category not in extracted_traits:
                        extracted_traits[category] = []
                    extracted_traits[category].append({
                        'dimension': dimension,
                        'level': level
                    })
                    break
    
    # Alternative pattern: look for lines containing trait descriptions
    lines = user_profile.split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Look for mentions of High/Medium/Low levels
        for level in ['High', 'Medium', 'Low']:
            if level.lower() in line.lower():
                # Try to extract the dimension name
                for category, dimensions in categories.items():
                    for dimension in dimensions:
                        if dimension.lower() in line.lower():
                            if category not in extracted_traits:
                                extracted_traits[category] = []
                            
                            # Check if this trait is already added
                            existing = [t for t in extracted_traits[category] if t['dimension'] == dimension]
                            if not existing:
                                extracted_traits[category].append({
                                    'dimension': dimension,
                                    'level': level
                                })
                            break
    
    return extracted_traits

@app.route('/clear_memory', methods=['POST'])
def clear_memory():
    session_id = session.get('memory_session_id')
    if not session_id or session_id not in memory_systems:
        return jsonify({'error': 'Memory system not initialized'}), 400
    
    memory_system = memory_systems[session_id]
    
    try:
        # Clear all memory files
        user_data_dir = memory_system.user_data_dir
        assistant_data_dir = memory_system.assistant_data_dir
        
        # Remove the entire user data directory
        if os.path.exists(user_data_dir):
            shutil.rmtree(user_data_dir)
        
        # Remove the entire assistant data directory  
        if os.path.exists(assistant_data_dir):
            shutil.rmtree(assistant_data_dir)
        
        # 从session中获取配置来重新初始化
        config = session.get('memory_config')
        if not config:
            return jsonify({'error': 'Configuration not found in session. Please re-initialize.'}), 400

        api_key = config['api_key']
        base_url = config['base_url']
        model = config['model']
        user_id = memory_system.user_id
        assistant_id = memory_system.assistant_id
        data_path = memory_system.data_storage_path
        
        # Create new memory system
        new_memory_system = Memcontext(
            user_id=user_id,
            openai_api_key=api_key,
            openai_base_url=base_url,
            data_storage_path=data_path,
            assistant_id=assistant_id,
            short_term_capacity=7,
            mid_term_capacity=200,
            long_term_knowledge_capacity=100,
            mid_term_heat_threshold=5.0,
            llm_model=model
        )
        
        # Replace the old memory system
        memory_systems[session_id] = new_memory_system
        
        return jsonify({'success': True, 'message': 'All memories cleared successfully'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/import_conversations', methods=['POST'])
def import_conversations():
    session_id = session.get('memory_session_id')
    if not session_id or session_id not in memory_systems:
        return jsonify({'error': 'Memory system not initialized'}), 400
    
    memory_system = memory_systems[session_id]
    data = request.json
    conversations = data.get('conversations', [])
    
    if not conversations:
        return jsonify({'error': 'No conversations provided'}), 400
    
    try:
        imported_count = 0
        for conv in conversations:
            user_input = conv.get('user_input', '')
            agent_response = conv.get('agent_response', '')
            timestamp = conv.get('timestamp', get_timestamp())
            
            if user_input and agent_response:
                # Add each conversation to memory system
                memory_system.add_memory(
                    user_input=user_input,
                    agent_response=agent_response,
                    timestamp=timestamp
                )
                imported_count += 1
            else:
                print(f"Skipping invalid conversation: {conv}")
        
        return jsonify({
            'success': True,
            'imported_count': imported_count,
            'message': f'Successfully imported {imported_count} conversations'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5019) 